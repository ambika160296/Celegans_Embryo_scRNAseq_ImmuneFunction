#
# @include "_analyzer_struct.mro"
#

#
# Copyright (c) 2022 10X Genomics, Inc. All rights reserved.
#

filetype csv;
filetype h5;
filetype html;
filetype json;
filetype pickle;
filetype binary;
#
# @include "_sc_antibody_analyzer_stages.mro"
#

#
# Copyright (c) 2021 10X Genomics, Inc. All rights reserved.
#

filetype csv;
filetype pdf;
filetype h5;
filetype json;
#
# @include "_antibody_analyzer.mro"
#

filetype pdf;
filetype csv;
filetype h5;
filetype json;
#
# @include "_cr_ana_stages.mro"
#

#
# Copyright (c) 2021 10X Genomics, Inc. All rights reserved.
#
# Code generated by cr_ana.  DO NOT EDIT.
#

filetype bincode.lz4;
filetype h5;
filetype npy;
#
# @include "_batch_correction_pca.mro"
#

filetype pickle;
#
# @include "_run_kmeans.mro"
#

filetype h5;
#
# @include "_sc_rna_analyzer_stages.mro"
#

#
# Copyright (c) 2019 10X Genomics, Inc. All rights reserved.
#

filetype csv;
filetype h5;
filetype html;
filetype json;
filetype pickle;
filetype binary;
#
# @include "_cr_aggr_stages.mro"
#

#
# Copyright (c) 2021 10X Genomics, Inc. All rights reserved.
#
# Code generated by cr_aggr.  DO NOT EDIT.
#

filetype csv;
filetype em.json;
filetype fa;
filetype fasta;
filetype h5;
filetype json;
filetype pb;
filetype vloupe;
#
# @include "_sc_crispr_analyzer_stages.mro"
#

#
# Copyright (c) 2018 10X Genomics, Inc. All rights reserved.
#

filetype csv;
filetype pdf;
filetype h5;
filetype json;
#
# @include "_crispr_analyzer.mro"
#

filetype pdf;
filetype csv;
filetype h5;
filetype json;
#
# @include "_sc_rna_aggregator_stages.mro"
#

#
# Copyright (c) 2022 10X Genomics, Inc. All rights reserved.
#

filetype bam;
filetype bam.bai;
filetype csv;
filetype tsv;
filetype fastq;
filetype json;
filetype h5;
filetype html;
filetype pickle;
#
# @include "_cr_vdj_stages.mro"
#

#
# Copyright (c) 2021 10X Genomics, Inc. All rights reserved.
#
# Code generated by cr_vdj.  DO NOT EDIT.
#

filetype arp.bincode;
filetype bam;
filetype bam.bai;
filetype bed;
filetype bin;
filetype bincode;
filetype bincode.lz4;
filetype csv;
filetype fa;
filetype fasta;
filetype fasta.fai;
filetype fastq;
filetype h5;
filetype html;
filetype json;
filetype json.lz4;
filetype pb;
filetype tsv;
filetype txt;
#
# @include "_vloupe_stages.mro"
#

#
# Copyright (c) 2017 10X Genomics, Inc. All rights reserved.
#

filetype csv;
filetype h5;
filetype pb;
filetype vloupe;
#
# @include "sc_vdj_aggregator.mro"
#

filetype json;
filetype vloupe;
#
# @include "_common_cloupe_stages.mro"
#

#
# Copyright (c) 2016 10X Genomics, Inc. All rights reserved.
#

filetype cloupe;
filetype csv;
filetype json;
filetype h5;
filetype txt;

#
# @include "_analyzer_struct.mro"
#

struct AnalyzerInputs(
    h5     filtered_matrices_h5,
    h5     molecule_info,
    map[]  aggr_library_info,
    bool   no_secondary_analysis,
    csv    use_genes,
    csv    exclude_genes,
    csv    use_bcs,
    int    num_analysis_bcs,
    int    random_seed,
    int    num_pca_bcs,
    int    num_pca_genes,
    int    num_principal_comps,
    bool   chemistry_batch_correction,
    int    cbc_knn,
    float  cbc_alpha,
    float  cbc_sigma,
    bool   cbc_realign_panorama,
    int    max_clusters,
    int    graphclust_neighbors,
    float  neighbor_a,
    float  neighbor_b,
    float  graphclust_resolution,
    int    tsne_perplexity,
    int    tsne_input_pcs,
    int    tsne_max_dims,
    int    tsne_max_iter,
    int    tsne_stop_lying_iter,
    int    tsne_mom_switch_iter,
    float  tsne_theta,
    int    umap_n_neighbors,
    int    umap_input_pcs,
    int    umap_max_dims,
    float  umap_min_dist,
    string umap_metric,
    int    force_cells,
    bool   skip_multigenome_analysis,
)

struct AnalyzerOutputs(
    path analysis,
    path analysis_csv,
    h5   cloupe_matrix_h5,
    json summary,
)

#
# @include "_cr_ana_stages.mro"
#

struct PcaOutputs(
    h5   pca_h5,
    path pca_csv,
)

#
# @include "_sc_rna_analyzer_stages.mro"
#

struct PcaOutputs(
    h5   pca_h5,
    path pca_csv,
)

#
# @include "_cr_aggr_stages.mro"
#

struct VdjAggrCsvLibrary(
    string      library_id,
    path        vdj_contig_info,
    string      donor,
    string      origin,
    map<string> meta,
)

struct VdjAggrInput(
    VdjAggrCsvLibrary[] libraries,
)

struct VdjAggrResults(
    csv    clonotypes,
    fa     donor_ref_fa,
    fasta  consensus_fasta,
    csv    filtered_contig_annotations_csv,
    csv    consensus_annotations_csv,
    json   web_summary_data,
    vloupe vloupe,
)

#
# @include "_cr_vdj_stages.mro"
#

struct VdjRefFastaFolder(
    fa regions,
    fa donor_regions,
)

struct VdjRefFolder(
    VdjRefFastaFolder fasta,
    json              reference,
)

struct FilterSwitch(
    bool asm_shared_contig,
    bool enclone_shared_contig,
    bool enclone_multiplet,
    bool enclone_umi,
)

#
# @include "rna/sc_rna_aggregator_cs.mro"
#

struct CountAggrOutputs(
    json   summary                       "Aggregation metrics summary JSON",
    path   analysis                      "Secondary analysis output CSV",
    path   crispr_analysis               "Crispr analysis output",
    path   filtered_feature_bc_matrix    "Filtered feature-barcode matrices MEX",
    h5     filtered_feature_bc_matrix_h5 "Filtered feature-barcode matrices HDF5" "filtered_feature_bc_matrix.h5",
    cloupe cloupe                        "Loupe Browser file",
)

struct VdjAggrOutputs(
    csv    clonotypes                      "Clonotypes csv",
    fasta  consensus_fasta                 "Clonotype consensus FASTA"                                   "consensus.fasta",
    csv    filtered_contig_annotations_csv "Annotations of filtered contigs with library metadata (CSV)" "filtered_contig_annotations.csv",
    csv    consensus_annotations_csv       "Clonotype consensus annotations (CSV)"                       "consensus_annotations.csv",
    vloupe vloupe                          "Loupe VDJ Browser file",
)

#
# @include "_sc_antibody_analyzer_stages.mro"
#

stage CALL_ANTIBODIES(
    in  h5   filtered_feature_counts_matrix,
    in  h5   molecule_info,
    in  bool is_antibody,
    out json antibody_histograms_json,
    out csv  antibody_isotype_correlations,
    out json antibody_treemap_json,
    src py   "stages/feature/call_antibodies",
) split (
) using (
    volatile = strict,
)

stage SUMMARIZE_ANTIBODY_ANALYSIS(
    in  csv  aggregate_barcodes,
    in  bool is_antibody,
    out path antibody_analysis,
    src py   "stages/feature/summarize_antibody_analysis",
) using (
    mem_gb = 4,
)

#
# @include "_antibody_analyzer.mro"
#

pipeline _ANTIBODY_ANALYZER(
    in  h5   filtered_feature_counts_matrix,
    in  h5   molecule_info,
    in  csv  aggregate_barcodes,
    in  bool is_antibody,
    out path antibody_analysis,
    out json antibody_histograms_json,
    out csv  antibody_isotype_correlations,
    out json antibody_treemap_json,
)
{
    # Currently makes histograms
    call CALL_ANTIBODIES(
        filtered_feature_counts_matrix = self.filtered_feature_counts_matrix,
        molecule_info = self.molecule_info,
        is_antibody   = self.is_antibody,
    )

    # Currently copies this file
    call SUMMARIZE_ANTIBODY_ANALYSIS(
        aggregate_barcodes = self.aggregate_barcodes,
        is_antibody        = self.is_antibody,
    )

    return (
        antibody_analysis             = SUMMARIZE_ANTIBODY_ANALYSIS.antibody_analysis,
        antibody_histograms_json      = CALL_ANTIBODIES.antibody_histograms_json,
        antibody_isotype_correlations = CALL_ANTIBODIES.antibody_isotype_correlations,
        antibody_treemap_json         = CALL_ANTIBODIES.antibody_treemap_json,
    )
}

#
# @include "_cr_ana_stages.mro"
#

stage RUN_DIFFERENTIAL_EXPRESSION_NG(
    in  h5          matrix_h5,
    in  h5          clustering_h5,
    in  bool        is_antibody_only,
    out h5          diffexp_h5,
    out path        diffexp_csv,
    src comp        "cr_ana martian diff_exp_stage",
) split (
    in  map[]       cluster_keys,
    out bincode.lz4 diffexp,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_GRAPH_CLUSTERING_NG(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    num_neighbors,
    in  float  neighbor_a,
    in  float  neighbor_b,
    in  int    input_pcs,
    in  float  resolution,
    in  int    random_seed,
    in  bool   is_antibody_only,
    in  int    threads,
    out h5     clusters_h5,
    out path   clusters_csv,
    src comp   "cr_ana martian graph_clustering_stage",
) split (
    in  string feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_PCA_NG(
    in  h5              matrix_h5,
    in  int             num_pca_genes,
    in  int             num_principal_comps,
    in  bool            is_antibody_only,
    in  map<PcaOutputs> pca_map,
    out h5              pca_h5,
    out path            pca_csv,
    src comp            "cr_ana martian pca_stage",
) split (
    in  string          feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_PCA2(
    in  h5  matrix_h5,
    in  int num_pcs,
    out npy dimred_matrix,
    src comp "cr_ana martian pca2_stage",
) split (
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_TSNE_NG(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  float  perplexity,
    in  int    input_pcs,
    in  int    max_dims,
    in  int    max_iter,
    in  int    stop_lying_iter,
    in  int    mom_switch_iter,
    in  float  theta,
    in  bool   is_antibody_only,
    out h5     tsne_h5,
    out path   tsne_csv,
    src comp   "cr_ana martian tsne_stage",
) split (
    in  int    tsne_dims,
    in  string feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_UMAP_NG(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  int    n_neighbors,
    in  int    input_pcs,
    in  int    max_dims,
    in  float  min_dist,
    in  string metric,
    in  bool   is_antibody_only,
    out h5     umap_h5,
    out path   umap_csv,
    src comp   "cr_ana martian umap_stage",
) split (
    in  int    umap_dims,
    in  string feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

#
# @include "_batch_correction_pca.mro"
#

stage PCA_PREP(
    in  h5     matrix_h5,
    in  bool   is_antibody_only,
    in  bool   is_atac,
    out float  mem_gb,
    out h5     filt_matrix,
    out string library_type,
    src py     "stages/analyzer/pca_prep",
) split (
) using (
    volatile = strict,
)

stage RUN_FBPCA_CORE(
    in  h5    filt_matrix_h5,
    in  int   num_pcs,
    in  float mem_gb,
    out npy   dimred_matrix,
    src py    "stages/analyzer/run_fbpca_core",
) split (
) using (
    volatile = strict,
)

stage POST_PCA(
    in  h5     matrix_h5,
    in  h5     filt_matrix_h5,
    in  npy    dimred_matrix_npy,
    in  float  mem_gb,
    out pickle dimred_matrix,
    out pickle matrix_barcode_feature_info,
    src py     "stages/analyzer/post_pca",
) split (
) using (
    volatile = strict,
)

# Replacement for the old RUN_FBPCA which uses the PCA implemented in scan-rs
pipeline RUN_BATCH_CORRECTION_PCA(
    in  h5     matrix_h5,
    in  int    num_pcs,
    in  bool   is_antibody_only,
    in  bool   is_atac,
    out pickle dimred_matrix,
    out pickle matrix_barcode_feature_info,
    out string library_type,
)
{
    call PCA_PREP(
        matrix_h5        = self.matrix_h5,
        is_antibody_only = self.is_antibody_only,
        is_atac          = self.is_atac,
    ) using (
        volatile = true,
    )

    call RUN_PCA2(
        matrix_h5 = PCA_PREP.filt_matrix,
        num_pcs   = self.num_pcs,
    ) using (
        volatile = true,
    )

    call POST_PCA(
        matrix_h5         = self.matrix_h5,
        filt_matrix_h5    = PCA_PREP.filt_matrix,
        dimred_matrix_npy = RUN_PCA2.dimred_matrix,
        mem_gb            = PCA_PREP.mem_gb,
    ) using (
        volatile = true,
    )

    return (
        dimred_matrix               = POST_PCA.dimred_matrix,
        matrix_barcode_feature_info = POST_PCA.matrix_barcode_feature_info,
        library_type                = PCA_PREP.library_type,
    )
}

#
# @include "_run_kmeans.mro"
#

stage RUN_KMEANS(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  int    max_clusters,
    in  int    num_bcs,
    in  int    num_pcs,
    out h5     kmeans_h5,
    out path   kmeans_csv,
    src py     "stages/analyzer/run_kmeans",
) split (
    in  int    n_clusters,
    in  string library,
) using (
    volatile = strict,
)

#
# @include "_sc_rna_analyzer_stages.mro"
#

stage ANALYZER_PREFLIGHT(
    in  bool   no_secondary_analysis,
    in  h5     filtered_matrices_h5,
    in  csv    use_genes,
    in  csv    exclude_genes,
    in  csv    use_bcs,
    in  int    num_analysis_bcs,
    in  int    force_cells,
    in  int    random_seed,
    in  int    num_pca_bcs,
    in  int    num_pca_genes,
    in  int    num_principal_comps,
    in  int    cbc_knn,
    in  float  cbc_alpha,
    in  float  cbc_sigma,
    in  bool   cbc_realign_panorama,
    in  int    max_clusters,
    in  int    graphclust_neighbors,
    in  float  neighbor_a,
    in  float  neighbor_b,
    in  int    tsne_perplexity,
    in  int    tsne_input_pcs,
    in  int    tsne_max_dims,
    in  int    tsne_max_iter,
    in  int    tsne_stop_lying_iter,
    in  int    tsne_mom_switch_iter,
    in  float  tsne_theta,
    in  int    umap_n_neighbors,
    in  int    umap_input_pcs,
    in  int    umap_max_dims,
    in  float  umap_min_dist,
    in  string umap_metric,
    in  bool   chemistry_batch_correction,
    in  bool   skip_multigenome_analysis,
    out bool   skip,
    out bool   is_antibody_only,
    out bool   disable_run_pca,
    out bool   disable_correct_chemistry_batch,
    out bool   skip_multigenome_analysis,
    src py     "stages/analyzer/analyzer_preflight",
) using (
    volatile = strict,
)

stage REANALYZER_PREFLIGHT(
    in  h5 filtered_matrices_h5,
    src py "stages/analyzer/reanalyzer_preflight",
) using (
    volatile = strict,
)

stage REANALYZE_VERIFY_SAMPLE_IDS(
    in  h5    matrix_h5,
    in  map[] sample_defs,
    out map[] sample_defs,
    src py    "stages/analyzer/reanalyze_verify_sample_ids",
) using (
    volatile = strict,
)

stage PREPROCESS_MATRIX(
    in  h5   matrix_h5,
    in  int  random_seed,
    in  csv  use_genes,
    in  csv  exclude_genes,
    in  csv  use_bcs,
    in  int  num_bcs,
    in  int  force_cells,
    in  bool get_peak_matrix,
    in  bool skip,
    in  bool is_antibody_only,
    in  bool disable_run_pca,
    in  bool disable_correct_chemistry_batch,
    in  bool skip_multigenome_analysis,
    out bool skip_antibody_analysis,
    out bool skip_antigen_analysis,
    out h5   cloupe_matrix_h5,
    out h5   preprocessed_matrix_h5,
    out bool is_multi_genome,
    out bool skip,
    out bool is_antibody_only,
    out bool disable_run_pca,
    out bool disable_correct_chemistry_batch,
    out bool skip_multigenome_analysis,
    src py   "stages/analyzer/preprocess_matrix",
) split (
) using (
    volatile = strict,
)

stage RUN_MULTIGENOME_ANALYSIS(
    in  h5   filtered_matrices_h5,
    in  bool is_multi_genome,
    out path multi_genome_csv,
    out path multi_genome_json,
    out json multi_genome_summary,
    src py   "stages/analyzer/run_multigenome_analysis",
) split (
) using (
    volatile = strict,
)

stage RUN_PCA(
    in  h5   matrix_h5,
    in  int  random_seed,
    in  int  num_pca_bcs,
    in  int  num_pca_genes,
    in  int  num_principal_comps,
    in  bool is_antibody_only,
    out h5   pca_h5,
    out path pca_csv,
    src py   "stages/analyzer/run_pca",
) split (
) using (
    volatile = strict,
)

stage RUN_FBPCA(
    in  h5     matrix_h5,
    in  map[]  library_info,
    in  int    num_pcs,
    in  bool   is_antibody_only,
    in  bool   is_atac,
    out pickle dimred_matrix,
    out pickle matrix_barcode_feature_info,
    src py     "stages/analyzer/run_fbpca",
) split (
) using (
    volatile = strict,
)

stage RUN_GRAPH_CLUSTERING(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    num_neighbors       "Use this many neighbors",
    in  float  neighbor_a          "Use larger of (a+b*log10(n_cells) neighbors or num_neighbors",
    in  float  neighbor_b          "Use larger of (a+b*log10(n_cells) neighbors or num_neighbors",
    in  int    num_bcs             "Use this many cell-barcodes in clustering",
    in  int    input_pcs           "Use top N PCs",
    in  int    balltree_leaf_size,
    in  string similarity_type     "Type of similarity to use (nn or snn)",
    in  int    random_seed         "Seed for random number generator",
    out h5     chunked_neighbors,
    out h5     clusters_h5,
    out path   clusters_csv,
    src py     "stages/analyzer/run_graph_clustering",
) split (
    in  pickle neighbor_index,
    in  h5     submatrix,
    in  int    row_start,
    in  int    total_rows,
    in  int    k_nearest,
    in  h5     use_bcs,
) using (
    volatile = strict,
)

stage MERGE_CLUSTERS(
    in  h5   matrix_h5,
    in  h5   pca_h5,
    in  h5   clusters_h5,
    out h5   clusters_h5,
    out path clusters_csv,
    src py   "stages/analyzer/merge_clusters",
) split (
) using (
    volatile = strict,
)

stage COMBINE_CLUSTERING(
    in  h5   kmeans_h5,
    in  path kmeans_csv,
    in  h5   graphclust_h5,
    in  path graphclust_csv,
    out h5   clustering_h5,
    out path clustering_csv,
    src py   "stages/analyzer/combine_clustering",
) using (
    volatile = strict,
)

stage RUN_DIFFERENTIAL_EXPRESSION(
    in  h5     matrix_h5,
    in  h5     clustering_h5,
    in  int    random_seed,
    in  int    max_clusters,
    in  bool   is_antibody_only,
    out h5     diffexp_h5,
    out path   diffexp_csv,
    src py     "stages/analyzer/run_differential_expression",
) split (
    in  string clustering_key,
) using (
    volatile = strict,
)

stage RUN_TSNE(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  int    perplexity,
    in  int    input_pcs,
    in  int    max_dims,
    in  int    max_iter,
    in  int    stop_lying_iter,
    in  int    mom_switch_iter,
    in  float  theta,
    in  bool   is_antibody_only,
    out h5     tsne_h5,
    out path   tsne_csv,
    src py     "stages/analyzer/run_tsne",
) split (
    in  int    tsne_dims,
    in  string feature_type,
) using (
    volatile = strict,
)

stage SUMMARIZE_ANALYSIS(
    in  h5    matrix_h5,
    in  h5    pca_h5,
    in  h5    clustering_h5,
    in  h5    diffexp_h5,
    in  h5    tsne_h5,
    in  h5    umap_h5,
    in  path  pca_csv,
    in  path  clustering_csv,
    in  path  diffexp_csv,
    in  path  tsne_csv,
    in  path  umap_csv,
    in  json  multi_genome_summary,
    in  path  multi_genome_csv,
    in  path  multi_genome_json,
    in  bool  is_multi_genome,
    in  bool  chemistry_batch_correction,
    in  float batch_score_before_correction,
    in  float batch_score_after_correction,
    out path  analysis,
    out path  analysis_csv,
    out json  summary,
    src py    "stages/analyzer/summarize_analysis",
) split (
) using (
    volatile = strict,
)

stage PARSE_PARAM_CSV(
    in  csv    params_csv,
    out csv    params_csv,
    out int    num_analysis_bcs,
    out int    random_seed,
    out int    num_pca_bcs,
    out int    num_pca_genes,
    out int    num_principal_comps,
    out int    cbc_knn,
    out float  cbc_alpha,
    out float  cbc_sigma,
    out bool   cbc_realign_panorama,
    out int    max_clusters,
    out int    graphclust_neighbors,
    out float  neighbor_a,
    out float  neighbor_b,
    out int    tsne_perplexity,
    out int    tsne_input_pcs,
    out int    tsne_max_dims,
    out int    tsne_max_iter,
    out int    tsne_stop_lying_iter,
    out int    tsne_mom_switch_iter,
    out float  tsne_theta,
    out int    umap_n_neighbors,
    out int    umap_input_pcs,
    out int    umap_max_dims,
    out float  umap_min_dist,
    out string umap_metric,
    src py     "stages/analyzer/parse_csv",
) using (
    volatile = strict,
)

stage SUMMARIZE_REANALYSIS(
    in  string sample_id,
    in  string sample_desc,
    in  h5     filtered_matrices,
    in  path   analysis,
    in  json   analyze_matrices_summary,
    in  json   antibody_histograms,
    in  json   antibody_treemap,
    out html   web_summary,
    out json   summary,
    out path   feature_bc_matrix_mex,
    src py     "stages/analyzer/summarize_reanalysis",
) split (
) using (
    volatile = strict,
) retain (
    summary,
)

stage CORRECT_CHEMISTRY_BATCH(
    in  pickle          dimred_matrix,
    in  pickle          matrix_barcode_feature_info,
    in  map[]           library_info,
    in  string          library_type,
    in  int             cbc_knn,
    in  float           cbc_alpha,
    in  float           cbc_sigma,
    in  bool            cbc_realign_panorama,
    out float           batch_score_before_correction,
    out float           batch_score_after_correction,
    out h5              aligned_pca_h5,
    out path            aligned_pca_csv,
    out map<PcaOutputs> aligned_pca_map,
    src py              "stages/analyzer/correct_chemistry_batch",
) split (
    in  int             batch_id,
    in  map             batch_to_bc_indices,
    in  pickle          ordered_dimred_matrix,
    in  pickle          idx_to_batch_id,
    in  bool            need_reorder_barcode,
    in  pickle          barcode_reorder_index,
    out binary          batch_nearest_neighbor,
) using (
    mem_gb   = 4,
    volatile = strict,
)

stage CHOOSE_DIMENSION_REDUCTION_OUTPUT(
    in  h5[]   pca_h5_list,
    in  path[] pca_csv_list,
    out h5     pca_h5,
    out path   pca_csv,
    src py     "stages/analyzer/choose_dimension_reduction_output",
) using (
    volatile = strict,
)

#
# @include "sc_rna_analyzer_ng.mro"
#

pipeline SC_RNA_ANALYZER_NG(
    in  csv                aggregate_barcodes,
    in  AnalyzerInputs     analyzer_inputs,
    out AnalyzerOutputs    common_analyzer,
    out _ANTIBODY_ANALYZER antibody_analyzer,
    out _ANTIBODY_ANALYZER antigen_analyzer,
    out csv                antibody_isotype_correlations,
    out h5                 clustering_h5,
)
{
    call ANALYZER_PREFLIGHT(
        * = self.analyzer_inputs,
    ) using (
        volatile = true,
    )

    call PREPROCESS_MATRIX(
        matrix_h5       = self.analyzer_inputs.filtered_matrices_h5,
        random_seed     = self.analyzer_inputs.random_seed,
        use_genes       = self.analyzer_inputs.use_genes,
        exclude_genes   = self.analyzer_inputs.exclude_genes,
        use_bcs         = self.analyzer_inputs.use_bcs,
        num_bcs         = self.analyzer_inputs.num_analysis_bcs,
        force_cells     = self.analyzer_inputs.force_cells,
        get_peak_matrix = false,
        *               = ANALYZER_PREFLIGHT,
    ) using (
        volatile = true,
    )

    call RUN_MULTIGENOME_ANALYSIS(
        filtered_matrices_h5 = self.analyzer_inputs.filtered_matrices_h5,
        is_multi_genome      = PREPROCESS_MATRIX.is_multi_genome,
    ) using (
        disabled = PREPROCESS_MATRIX.skip_multigenome_analysis,
        volatile = true,
    )

    call RUN_BATCH_CORRECTION_PCA(
        matrix_h5        = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        num_pcs          = self.analyzer_inputs.num_principal_comps,
        is_antibody_only = PREPROCESS_MATRIX.is_antibody_only,
        is_atac          = false,
    ) using (
        disabled = PREPROCESS_MATRIX.disable_correct_chemistry_batch,
    )

    call CORRECT_CHEMISTRY_BATCH(
        dimred_matrix               = RUN_BATCH_CORRECTION_PCA.dimred_matrix,
        matrix_barcode_feature_info = RUN_BATCH_CORRECTION_PCA.matrix_barcode_feature_info,
        library_info                = self.analyzer_inputs.aggr_library_info,
        library_type                = RUN_BATCH_CORRECTION_PCA.library_type,
        cbc_knn                     = self.analyzer_inputs.cbc_knn,
        cbc_alpha                   = self.analyzer_inputs.cbc_alpha,
        cbc_sigma                   = self.analyzer_inputs.cbc_sigma,
        cbc_realign_panorama        = self.analyzer_inputs.cbc_realign_panorama,
    ) using (
        disabled = PREPROCESS_MATRIX.disable_correct_chemistry_batch,
        volatile = true,
    )

    call RUN_PCA_NG as RUN_PCA(
        matrix_h5           = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        num_pca_genes       = self.analyzer_inputs.num_pca_genes,
        num_principal_comps = self.analyzer_inputs.num_principal_comps,
        pca_map             = CORRECT_CHEMISTRY_BATCH.aligned_pca_map,
        is_antibody_only    = PREPROCESS_MATRIX.is_antibody_only,
    ) using (
        disabled = PREPROCESS_MATRIX.disable_run_pca,
        volatile = true,
    )

    call RUN_KMEANS(
        matrix_h5    = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        pca_h5       = RUN_PCA.pca_h5,
        random_seed  = self.analyzer_inputs.random_seed,
        max_clusters = self.analyzer_inputs.max_clusters,
        num_bcs      = null,
        num_pcs      = null,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
        volatile = true,
    )

    call RUN_GRAPH_CLUSTERING_NG as RUN_GRAPH_CLUSTERING(
        matrix_h5        = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        pca_h5           = RUN_PCA.pca_h5,
        num_neighbors    = self.analyzer_inputs.graphclust_neighbors,
        neighbor_a       = self.analyzer_inputs.neighbor_a,
        neighbor_b       = self.analyzer_inputs.neighbor_b,
        input_pcs        = null,
        resolution       = self.analyzer_inputs.graphclust_resolution,
        random_seed      = self.analyzer_inputs.random_seed,
        is_antibody_only = PREPROCESS_MATRIX.is_antibody_only,
        threads          = 4,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
        volatile = true,
    )

    call COMBINE_CLUSTERING(
        kmeans_h5      = RUN_KMEANS.kmeans_h5,
        kmeans_csv     = RUN_KMEANS.kmeans_csv,
        graphclust_h5  = RUN_GRAPH_CLUSTERING.clusters_h5,
        graphclust_csv = RUN_GRAPH_CLUSTERING.clusters_csv,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
        volatile = true,
    )

    call RUN_DIFFERENTIAL_EXPRESSION_NG as RUN_DIFFERENTIAL_EXPRESSION(
        matrix_h5        = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        clustering_h5    = COMBINE_CLUSTERING.clustering_h5,
        is_antibody_only = PREPROCESS_MATRIX.is_antibody_only,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
        volatile = true,
    )

    call RUN_TSNE_NG as RUN_TSNE(
        matrix_h5        = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        pca_h5           = RUN_PCA.pca_h5,
        random_seed      = self.analyzer_inputs.random_seed,
        perplexity       = self.analyzer_inputs.tsne_perplexity,
        input_pcs        = self.analyzer_inputs.tsne_input_pcs,
        max_dims         = self.analyzer_inputs.tsne_max_dims,
        max_iter         = self.analyzer_inputs.tsne_max_iter,
        stop_lying_iter  = self.analyzer_inputs.tsne_stop_lying_iter,
        mom_switch_iter  = self.analyzer_inputs.tsne_mom_switch_iter,
        theta            = self.analyzer_inputs.tsne_theta,
        is_antibody_only = PREPROCESS_MATRIX.is_antibody_only,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
        volatile = true,
    )

    call RUN_UMAP_NG as RUN_UMAP(
        matrix_h5        = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        pca_h5           = RUN_PCA.pca_h5,
        random_seed      = self.analyzer_inputs.random_seed,
        n_neighbors      = self.analyzer_inputs.umap_n_neighbors,
        input_pcs        = self.analyzer_inputs.umap_input_pcs,
        max_dims         = self.analyzer_inputs.umap_max_dims,
        min_dist         = self.analyzer_inputs.umap_min_dist,
        metric           = self.analyzer_inputs.umap_metric,
        is_antibody_only = PREPROCESS_MATRIX.is_antibody_only,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
        volatile = true,
    )

    call SUMMARIZE_ANALYSIS(
        matrix_h5                     = PREPROCESS_MATRIX.preprocessed_matrix_h5,
        pca_h5                        = RUN_PCA.pca_h5,
        clustering_h5                 = COMBINE_CLUSTERING.clustering_h5,
        diffexp_h5                    = RUN_DIFFERENTIAL_EXPRESSION.diffexp_h5,
        tsne_h5                       = RUN_TSNE.tsne_h5,
        umap_h5                       = RUN_UMAP.umap_h5,
        pca_csv                       = RUN_PCA.pca_csv,
        clustering_csv                = COMBINE_CLUSTERING.clustering_csv,
        diffexp_csv                   = RUN_DIFFERENTIAL_EXPRESSION.diffexp_csv,
        tsne_csv                      = RUN_TSNE.tsne_csv,
        umap_csv                      = RUN_UMAP.umap_csv,
        multi_genome_summary          = RUN_MULTIGENOME_ANALYSIS.multi_genome_summary,
        multi_genome_csv              = RUN_MULTIGENOME_ANALYSIS.multi_genome_csv,
        multi_genome_json             = RUN_MULTIGENOME_ANALYSIS.multi_genome_json,
        is_multi_genome               = PREPROCESS_MATRIX.is_multi_genome,
        chemistry_batch_correction    = self.analyzer_inputs.chemistry_batch_correction,
        batch_score_before_correction = CORRECT_CHEMISTRY_BATCH.batch_score_before_correction,
        batch_score_after_correction  = CORRECT_CHEMISTRY_BATCH.batch_score_after_correction,
    ) using (
        disabled = PREPROCESS_MATRIX.skip,
    )

    # Note this stage uses the original and the the preprocessed matrix.
    call _ANTIBODY_ANALYZER(
        filtered_feature_counts_matrix = self.analyzer_inputs.filtered_matrices_h5,
        molecule_info      = self.analyzer_inputs.molecule_info,
        aggregate_barcodes = self.aggregate_barcodes,
        is_antibody        = true,
    ) using (
        disabled = PREPROCESS_MATRIX.skip_antibody_analysis,
    )

    call _ANTIBODY_ANALYZER as _ANTIGEN_ANALYZER(
        filtered_feature_counts_matrix = self.analyzer_inputs.filtered_matrices_h5,
        molecule_info      = self.analyzer_inputs.molecule_info,
        aggregate_barcodes = self.aggregate_barcodes,
        is_antibody        = false,
    ) using (
        disabled = PREPROCESS_MATRIX.skip_antigen_analysis,
    )

    return (
        antibody_analyzer             = _ANTIBODY_ANALYZER,
        antigen_analyzer              = _ANTIGEN_ANALYZER,
        antibody_isotype_correlations = _ANTIBODY_ANALYZER.antibody_isotype_correlations,
        clustering_h5                 = COMBINE_CLUSTERING.clustering_h5,
        common_analyzer               = {
            analysis:         SUMMARIZE_ANALYSIS.analysis,
            analysis_csv:     SUMMARIZE_ANALYSIS.analysis_csv,
            cloupe_matrix_h5: PREPROCESS_MATRIX.cloupe_matrix_h5,
            summary:          SUMMARIZE_ANALYSIS.summary,
        },
    )
}

#
# @include "_cr_aggr_stages.mro"
#

stage MERGE_MOLECULES(
    in  map[]      sample_defs,
    in  map[]      libraries,
    out h5         merged_molecules,
    out map<int[]> gem_group_barcode_ranges,
    src comp       "cr_aggr martian merge_molecules",
) split (
    in  map        sample_def,
    out path       trimmed_molecules,
    out map        sample_def,
) using (
    volatile = strict,
)

stage PROCESS_VDJ_PROTO(
    in  VdjAggrCsvLibrary[] libraries,
    in  map                 count_gem_well_map,
    out string              receptor,
    out map                 gem_well_map,
    src comp                "cr_aggr martian process_vdj_proto",
)

stage SETUP_VDJ_AGGR(
    in  VdjAggrCsvLibrary[] libraries,
    in  map                 gem_well_map,
    in  string              receptor,
    out json[]              contig_ann_json_files,
    out csv                 enclone_input_csv,
    out em.json             enclone_gem_well_meta,
    out path                vdj_reference_path,
    out json                combined_ann_json,
    src comp                "cr_aggr martian setup_vdj_aggr",
) split (
    in  int                 chunk_id,
    out json                chunk_ann_json,
    out map                 enclone_meta_row,
    out map                 enclone_gem_well_info,
)

stage RUN_ENCLONE_AGGR(
    in  json[]  contig_ann_json_files,
    in  csv     enclone_input_csv,
    in  em.json enclone_gem_well_meta,
    in  path    vdj_reference_path,
    out pb      enclone_output,
    out fa      donor_ref_fa,
    src comp    "cr_aggr martian run_enclone_aggr",
) using (
    mem_gb  = 9,
    threads = 4,
)

stage PARSE_AGGR_CSV(
    in  path           pipestance_root,
    in  csv            aggregation_csv,
    out csv            aggregation_csv,
    out map[]          count_libraries,
    out VdjAggrInput[] vdj_aggr_inputs,
    out bool           disable_count_aggr,
    out bool           disable_vdj_aggr,
    src comp           "cr_aggr martian parse_aggr_csv",
)

stage WRITE_CONTIG_PROTO(
    in  path   vdj_reference_path,
    in  json   contig_annotations_json,
    in  json   metrics_summary_json,
    in  string receptor,
    in  int[]  gem_wells,
    in  json   cell_barcodes,
    in  string sample_id,
    in  string sample_desc,
    in  string multi_config_sha,
    out pb     vdj_contig_info,
    src comp   "cr_aggr martian write_contig_proto",
)

stage MATCH_VDJ_AGGR_OUTS(
    in  string[]       receptors,
    in  csv[]          clonotypes,
    in  fa[]           donor_ref_fas,
    in  fasta[]        consensus_fastas,
    in  path[]         vdj_reference_paths,
    in  csv[]          filtered_contig_annotations_csvs,
    in  csv[]          consensus_annotations_csvs,
    in  json[]         web_summary_data,
    in  vloupe[]       vloupes,
    out VdjAggrResults vdj_t_results,
    out VdjAggrResults vdj_t_gd_results,
    out VdjAggrResults vdj_b_results,
    out path           vdj_reference_path,
    src comp           "cr_aggr martian match_vdj_outs",
)

stage WRITE_AGGR_ANN(
    in  em.json enclone_gem_well_meta,
    in  csv     annotation_csv,
    out csv     augmented_annotation_csv,
    src comp    "cr_aggr martian write_aggr_ann",
)

stage WRITE_WEB_SUMMARY_JSON(
    in  path                vdj_reference_path,
    in  VdjAggrCsvLibrary[] libraries,
    in  pb                  enclone_output,
    in  em.json             enclone_gem_well_meta,
    in  string              sample_id,
    in  string              sample_desc,
    in  csv                 clonotypes_csv,
    in  string              receptor,
    out json                web_summary_content,
    out json                per_origin_hist,
    src comp                "cr_aggr martian write_ws_json",
)

#
# @include "_sc_crispr_analyzer_stages.mro"
#

stage CALL_PROTOSPACERS(
    in  csv  filtered_barcodes,
    in  h5   filtered_feature_counts_matrix,
    in  json counter_metrics_json,
    out csv  protospacer_calls_summary,
    out csv  protospacer_calls_per_cell,
    out json protospacer_call_metrics_json,
    out json cells_per_protospacer,
    out json protospacer_umi_thresholds_json,
    out csv  protospacer_umi_thresholds_csv,
    src py   "stages/feature/call_protospacers",
) using (
    mem_gb = 16,
)

stage MEASURE_PERTURBATIONS(
    in  csv  protospacer_calls_per_cell,
    in  h5   filtered_feature_counts_matrix,
    in  csv  feature_reference,
    in  bool by_feature,
    in  bool ignore_multiples,
    out csv  perturbation_efficiencies,
    out path perturbation_effects_path,
    src py   "stages/feature/measure_perturbations",
) split (
)

stage SUMMARIZE_CRISPR_ANALYSIS(
    in  csv  feature_reference,
    in  csv  protospacer_calls_summary,
    in  csv  protospacer_calls_per_cell,
    in  json cells_per_protospacer,
    in  csv  protospacer_umi_thresholds_csv,
    in  json protospacer_umi_thresholds_json,
    in  csv  perturbation_efficiencies_by_feature,
    in  csv  perturbations_efficiencies_by_target,
    in  path perturbation_effects_by_feature,
    in  path perturbation_effects_by_target,
    out path crispr_analysis,
    src py   "stages/feature/summarize_crispr_analysis",
) using (
    mem_gb = 4,
)

#
# @include "_crispr_analyzer.mro"
#

pipeline _CRISPR_ANALYZER(
    in  h5   filtered_feature_counts_matrix,
    in  csv  filtered_barcodes,
    in  csv  feature_reference,
    in  json counter_metrics_json,
    out json cells_per_protospacer,
    out json crispr_analysis_metrics,
    out path crispr_analysis,
)
{
    call CALL_PROTOSPACERS(
        filtered_barcodes    = self.filtered_barcodes,
        filtered_feature_counts_matrix = self.filtered_feature_counts_matrix,
        counter_metrics_json = self.counter_metrics_json,
    )

    call MEASURE_PERTURBATIONS as _PERTURBATIONS_BY_FEATURE(
        protospacer_calls_per_cell = CALL_PROTOSPACERS.protospacer_calls_per_cell,
        filtered_feature_counts_matrix = self.filtered_feature_counts_matrix,
        feature_reference          = self.feature_reference,
        by_feature                 = true,
        ignore_multiples           = false,
    )

    call MEASURE_PERTURBATIONS as _PERTURBATIONS_BY_TARGET(
        protospacer_calls_per_cell = CALL_PROTOSPACERS.protospacer_calls_per_cell,
        filtered_feature_counts_matrix = self.filtered_feature_counts_matrix,
        feature_reference          = self.feature_reference,
        by_feature                 = false,
        ignore_multiples           = false,
    )

    call SUMMARIZE_CRISPR_ANALYSIS(
        feature_reference          = self.feature_reference,
        protospacer_calls_summary  = CALL_PROTOSPACERS.protospacer_calls_summary,
        protospacer_calls_per_cell = CALL_PROTOSPACERS.protospacer_calls_per_cell,
        cells_per_protospacer      = CALL_PROTOSPACERS.cells_per_protospacer,
        protospacer_umi_thresholds_csv = CALL_PROTOSPACERS.protospacer_umi_thresholds_csv,
        protospacer_umi_thresholds_json = CALL_PROTOSPACERS.protospacer_umi_thresholds_json,
        perturbation_efficiencies_by_feature = _PERTURBATIONS_BY_FEATURE.perturbation_efficiencies,
        perturbations_efficiencies_by_target = _PERTURBATIONS_BY_TARGET.perturbation_efficiencies,
        perturbation_effects_by_feature = _PERTURBATIONS_BY_FEATURE.perturbation_effects_path,
        perturbation_effects_by_target = _PERTURBATIONS_BY_TARGET.perturbation_effects_path,
    )

    return (
        cells_per_protospacer   = CALL_PROTOSPACERS.cells_per_protospacer,
        crispr_analysis_metrics = CALL_PROTOSPACERS.protospacer_call_metrics_json,
        crispr_analysis         = SUMMARIZE_CRISPR_ANALYSIS.crispr_analysis,
    )
}

#
# @include "_sc_rna_aggregator_stages.mro"
#

stage AGGREGATOR_PREFLIGHT(
    in  map[]  sample_defs,
    in  string normalization_mode,
    in  bool   is_pd,
    src py     "stages/aggregator/aggregator_preflight",
) using (
    volatile = strict,
)

stage PARSE_CSV(
    in  path   pipestance_root,
    in  csv    aggregation_csv,
    in  bool   reanalyze,
    in  h5     matrix_h5,
    in  string product_type,
    out csv    aggregation_csv,
    out map[]  sample_defs,
    src py     "stages/aggregator/parse_csv",
) using (
    volatile = strict,
)

stage CHECK_MOLECULE_INFO_VERSION(
    in  map[]  sample_defs,
    in  string product_type,
    out map[]  updated_sample_defs,
    src py     "stages/aggregator/check_molecule_info_version",
) split (
    in  int    mol_h5_version,
    in  map    sample_def,
    out map    updated_sample_def,
) using (
    volatile = strict,
)

stage SETUP_SAMPLES(
    in  map[] sample_defs,
    out map   gem_group_index,
    out map[] libraries,
    out json  gem_group_index_json,
    out bool  chemistry_batch_correction,
    out bool  disable_crispr_aggr,
    src py    "stages/aggregator/setup_samples",
) using (
    volatile = strict,
)

stage NORMALIZE_DEPTH(
    in  map        gem_group_index,
    in  h5         molecules,
    in  string     normalization_mode,
    in  map<int[]> gem_group_barcode_ranges,
    in  float      targeted_depth_factor,
    out h5[]       raw_matrices_h5,
    out int        raw_nnz,
    out h5[]       filtered_matrices_h5,
    out int        filtered_nnz,
    out json       summary,
    src py         "stages/aggregator/normalize_depth",
) split (
    in  float[]    frac_reads_kept,
    in  int[]      num_cells,
    in  int        chunk_start,
    in  int        chunk_len,
    in  json       reads_per_library,
    out json       chunk_summary,
    out h5         raw_matrix_h5,
    out h5         filtered_matrix_h5,
) using (
    mem_gb   = 4,
    volatile = strict,
)

stage WRITE_MATRICES(
    in  map[] sample_defs,
    in  map   gem_group_index,
    in  h5    molecules,
    in  h5[]  raw_matrices_h5,
    in  int   raw_nnz,
    in  h5[]  filtered_matrices_h5,
    in  int   filtered_nnz,
    in  json  summary,
    in  bool  is_pd,
    out h5    raw_matrix_h5,
    out h5    filtered_matrix_h5,
    out path  filtered_matrix_mex,
    out h5    barcode_summary_h5,
    out json  summary,
    src py    "stages/aggregator/write_matrices",
) split (
) using (
    volatile = strict,
)

stage CRISPR_AGGR_INPUT_PREP(
    in  h5   merged_molecules,
    out csv  filtered_barcodes,
    out csv  feature_reference,
    out json counter_metrics_json,
    src py   "stages/aggregator/crispr_aggr_input_prep",
) using (
    mem_gb   = 4,
    volatile = strict,
)

stage CHECK_INVARIANTS(
    in  map[] input_sample_defs,
    in  h5    merged_raw_gene_bc_matrices_h5,
    out json  summary,
    src py    "stages/aggregator/check_invariants",
) split (
) using (
    volatile = strict,
)

stage SUMMARIZE_AGGREGATED_REPORTS(
    in  string sample_id,
    in  string sample_desc,
    in  map    gem_group_index,
    in  h5     filtered_matrices_h5,
    in  path   analysis,
    in  json   normalize_depth_summary,
    in  json   analyze_matrices_summary,
    in  json   antibody_histograms,
    in  json   antibody_treemap,
    in  json   crispr_analysis_metrics,
    in  string product_type,
    out json   summary,
    out html   web_summary,
    out json   web_summary_data,
    src py     "stages/aggregator/summarize_aggregated_reports",
) split (
) using (
    volatile = strict,
)

#
# @include "sc_rna_aggregator.mro"
#

pipeline SC_RNA_AGGREGATOR(
    in  string sample_id,
    in  string sample_desc,
    in  map[]  sample_defs,
    in  string normalization_mode,
    in  bool   no_secondary_analysis,
    in  int    num_analysis_bcs,
    in  int    num_pca_bcs,
    in  int    num_pca_genes,
    in  int    num_principal_comps,
    in  int    cbc_knn,
    in  float  cbc_alpha,
    in  float  cbc_sigma,
    in  bool   cbc_realign_panorama,
    in  int    max_clusters,
    in  int    graphclust_neighbors,
    in  float  neighbor_a,
    in  float  neighbor_b,
    in  int    tsne_perplexity,
    in  int    tsne_input_pcs,
    in  int    random_seed,
    in  int    tsne_max_dims,
    in  int    tsne_max_iter,
    in  int    tsne_stop_lying_iter,
    in  int    tsne_mom_switch_iter,
    in  float  tsne_theta,
    in  string product_type,
    in  bool   is_pd,
    out h5     raw_gene_bc_matrices_h5,
    out h5     filtered_gene_bc_matrices_h5,
    out path   filtered_gene_bc_matrices_mex,
    out h5     molecule_info,
    out path   analysis,
    out path   crispr_analysis,
    out path   analysis_csv,
    out json   analysis_summary,
    out json   summary,
    out html   web_summary,
    out json   web_summary_data,
    out map    gem_group_index,
    out json   gem_group_index_json,
)
{
    call AGGREGATOR_PREFLIGHT(
        sample_defs        = self.sample_defs,
        normalization_mode = self.normalization_mode,
        is_pd              = self.is_pd,
    ) using (
        preflight = true,
    )

    call SETUP_SAMPLES(
        sample_defs = self.sample_defs,
    ) using (
        volatile = true,
    )

    call MERGE_MOLECULES(
        sample_defs = self.sample_defs,
        libraries   = SETUP_SAMPLES.libraries,
    ) using (
        volatile = true,
    )

    call NORMALIZE_DEPTH(
        gem_group_index          = SETUP_SAMPLES.gem_group_index,
        normalization_mode       = self.normalization_mode,
        molecules                = MERGE_MOLECULES.merged_molecules,
        gem_group_barcode_ranges = MERGE_MOLECULES.gem_group_barcode_ranges,
        targeted_depth_factor    = 2,
    )

    call WRITE_MATRICES(
        sample_defs          = self.sample_defs,
        gem_group_index      = SETUP_SAMPLES.gem_group_index,
        molecules            = MERGE_MOLECULES.merged_molecules,
        raw_matrices_h5      = NORMALIZE_DEPTH.raw_matrices_h5,
        filtered_matrices_h5 = NORMALIZE_DEPTH.filtered_matrices_h5,
        raw_nnz              = NORMALIZE_DEPTH.raw_nnz,
        filtered_nnz         = NORMALIZE_DEPTH.filtered_nnz,
        summary              = NORMALIZE_DEPTH.summary,
        is_pd                = self.is_pd,
    )

    call CRISPR_AGGR_INPUT_PREP(
        merged_molecules = MERGE_MOLECULES.merged_molecules,
    ) using (
        disabled = SETUP_SAMPLES.disable_crispr_aggr,
    )

    call _CRISPR_ANALYZER(
        filtered_feature_counts_matrix = WRITE_MATRICES.filtered_matrix_h5,
        filtered_barcodes    = CRISPR_AGGR_INPUT_PREP.filtered_barcodes,
        feature_reference    = CRISPR_AGGR_INPUT_PREP.feature_reference,
        counter_metrics_json = CRISPR_AGGR_INPUT_PREP.counter_metrics_json,
    ) using (
        disabled = SETUP_SAMPLES.disable_crispr_aggr,
    )

    call SC_RNA_ANALYZER_NG as SC_RNA_ANALYZER(
        aggregate_barcodes = null,
        analyzer_inputs    = {
            aggr_library_info:          SETUP_SAMPLES.libraries,
            cbc_alpha:                  self.cbc_alpha,
            cbc_knn:                    self.cbc_knn,
            cbc_realign_panorama:       self.cbc_realign_panorama,
            cbc_sigma:                  self.cbc_sigma,
            chemistry_batch_correction: SETUP_SAMPLES.chemistry_batch_correction,
            exclude_genes:              null,
            filtered_matrices_h5:       WRITE_MATRICES.filtered_matrix_h5,
            force_cells:                null,
            graphclust_neighbors:       self.graphclust_neighbors,
            graphclust_resolution:      null,
            max_clusters:               self.max_clusters,
            molecule_info:              MERGE_MOLECULES.merged_molecules,
            neighbor_a:                 self.neighbor_a,
            neighbor_b:                 self.neighbor_b,
            no_secondary_analysis:      self.no_secondary_analysis,
            num_analysis_bcs:           self.num_analysis_bcs,
            num_pca_bcs:                self.num_pca_bcs,
            num_pca_genes:              self.num_pca_genes,
            num_principal_comps:        self.num_principal_comps,
            random_seed:                self.random_seed,
            skip_multigenome_analysis:  false,
            tsne_input_pcs:             self.tsne_input_pcs,
            tsne_max_dims:              self.tsne_max_dims,
            tsne_max_iter:              self.tsne_max_iter,
            tsne_mom_switch_iter:       self.tsne_mom_switch_iter,
            tsne_perplexity:            self.tsne_perplexity,
            tsne_stop_lying_iter:       self.tsne_stop_lying_iter,
            tsne_theta:                 self.tsne_theta,
            umap_input_pcs:             null,
            umap_max_dims:              null,
            umap_metric:                null,
            umap_min_dist:              null,
            umap_n_neighbors:           null,
            use_bcs:                    null,
            use_genes:                  null,
        },
    )

    call SUMMARIZE_AGGREGATED_REPORTS(
        sample_id                = self.sample_id,
        sample_desc              = self.sample_desc,
        gem_group_index          = SETUP_SAMPLES.gem_group_index,
        filtered_matrices_h5     = WRITE_MATRICES.filtered_matrix_h5,
        analysis                 = SC_RNA_ANALYZER.common_analyzer.analysis,
        normalize_depth_summary  = WRITE_MATRICES.summary,
        analyze_matrices_summary = SC_RNA_ANALYZER.common_analyzer.summary,
        antibody_histograms      = SC_RNA_ANALYZER.antibody_analyzer.antibody_histograms_json,
        antibody_treemap         = SC_RNA_ANALYZER.antibody_analyzer.antibody_treemap_json,
        crispr_analysis_metrics  = _CRISPR_ANALYZER.crispr_analysis_metrics,
        product_type             = self.product_type,
    )

    return (
        filtered_gene_bc_matrices_h5  = WRITE_MATRICES.filtered_matrix_h5,
        filtered_gene_bc_matrices_mex = WRITE_MATRICES.filtered_matrix_mex,
        raw_gene_bc_matrices_h5       = WRITE_MATRICES.raw_matrix_h5,
        analysis                      = SC_RNA_ANALYZER.common_analyzer.analysis,
        crispr_analysis               = _CRISPR_ANALYZER.crispr_analysis,
        analysis_csv                  = SC_RNA_ANALYZER.common_analyzer.analysis_csv,
        analysis_summary              = SC_RNA_ANALYZER.common_analyzer.summary,
        summary                       = SUMMARIZE_AGGREGATED_REPORTS.summary,
        web_summary                   = SUMMARIZE_AGGREGATED_REPORTS.web_summary,
        web_summary_data              = SUMMARIZE_AGGREGATED_REPORTS.web_summary_data,
        gem_group_index               = SETUP_SAMPLES.gem_group_index,
        gem_group_index_json          = SETUP_SAMPLES.gem_group_index_json,
        molecule_info                 = MERGE_MOLECULES.merged_molecules,
    )
}

#
# @include "_cr_vdj_stages.mro"
#

stage COPY_VDJ_REFERENCE(
    in  path         vdj_reference_path,
    in  fa           vdj_t_donor_ref_fa,
    in  fa           vdj_t_gd_donor_ref_fa,
    in  fa           vdj_b_donor_ref_fa,
    out VdjRefFolder vdj_reference,
    src comp         "cr_vdj martian copy_vdj_reference",
)

stage SUMMARIZE_VDJ_FILTERS(
    in  string   sample_id,
    in  string   sample_description,
    in  json     all_contig_annotations,
    in  json.lz4 asm_filter_diagnostics,
    in  json     enclone_barcode_fate,
    in  h5       raw_matrix_h5,
    out html     filter_summary,
    out json     metrics_summary,
    src comp     "cr_vdj martian summarize_vdj_filters",
) using (
    mem_gb = 4,
)

stage CREATE_BARCODE_CSV(
    in  h5  gex_filtered_matrix,
    in  csv vdj_filtered_annotations,
    out csv per_barcode_csv,
    src comp "cr_vdj martian create_barcode_csv",
)

stage RUN_ENCLONE(
    in  FilterSwitch filter_switch,
    in  path         vdj_reference_path,
    in  json         contig_annotations,
    in  string       receptor,
    out json         summary,
    out pb           enclone_output,
    out fa           donor_ref_fa,
    out json         barcode_fate,
    out bool         disable_vloupe,
    src comp         "cr_vdj martian assigner",
) using (
    mem_gb  = 5,
    threads = -4,
)

stage WRITE_CLONOTYPE_OUTS(
    in  string receptor,
    in  pb     enclone_output,
    out csv    clonotypes_csv,
    src comp   "cr_vdj martian write_clonotype_outs",
) using (
    mem_gb = 8,
)

stage FILL_CLONOTYPE_INFO(
    in  json contig_annotations,
    in  pb   enclone_output,
    out json all_contig_annotations_json,
    src comp "cr_vdj martian fill_clonotype_info",
) using (
    mem_gb = 2,
)

stage HANDLE_NO_VDJ_REF(
    in  json asm_contig_json,
    in  json clonotype_contig_json,
    in  bool has_no_vdj_ref,
    out json final_contig_annotations,
    src comp "cr_vdj martian handle_no_ref",
)

stage WRITE_CONCAT_REF_OUTS(
    in  pb        enclone_output,
    in  json      all_contig_annotations_json,
    out bam       concat_ref_bam,
    out bam.bai   concat_ref_bam_bai,
    out fasta     concat_ref_fasta,
    out fasta.fai concat_ref_fasta_fai,
    src comp      "cr_vdj martian write_concat_ref_outs",
) using (
    mem_gb  = 4,
    threads = 4,
)

stage WRITE_CONSENSUS_BAM(
    in  pb      enclone_output,
    in  json    all_contig_annotations_json,
    out bam     consensus_bam,
    out bam.bai consensus_bam_bai,
    src comp    "cr_vdj martian write_consensus_bam",
) using (
    mem_gb  = 4,
    threads = 4,
)

stage WRITE_CONSENSUS_TXT(
    in  pb        enclone_output,
    out fasta     consensus_fasta,
    out fasta.fai consensus_fasta_fai,
    out csv       consensus_annotations_csv,
    src comp      "cr_vdj martian write_consensus_txt",
) using (
    mem_gb  = 4,
    threads = 1,
)

stage ASSEMBLE_VDJ(
    in  bincode.lz4[] bc_sorted_rna_reads,
    in  bool          paired_end,
    in  path          vdj_reference_path,
    in  string        receptor,
    in  int           n50_n50_rpu,
    in  int           npairs,
    in  bool          denovo,
    in  int           force_cells,
    in  path          inner_enrichment_primers,
    in  int           total_read_pairs,
    in  json          corrected_bc_counts,
    in  FilterSwitch  filter_switch,
    out bam           contig_bam,
    out bam.bai       contig_bam_bai,
    out tsv           summary_tsv,
    out tsv           umi_summary_tsv,
    out json          metrics_summary_json,
    out json          contig_annotations,
    out csv           barcode_support,
    out json[]        barcodes_in_chunks,
    out arp.bincode   assemblable_reads_per_bc,
    out json.lz4      filter_diagnostics,
    out txt           align_info,
    out fastq         unmapped_sample_fastq,
    out txt           report,
    src comp          "cr_vdj martian assembly",
) split (
    in  bincode.lz4   chunk_rna_reads,
    in  bool          perf_track,
    in  int           chunk_id,
    out json          barcodes_in_chunk,
    out bin           barcode_data,
    out bin           barcode_data_sum,
    out bin           barcode_data_brief,
    out bincode       outs_builder,
) retain (
    filter_diagnostics,
)

stage CREATE_AIRR_TSV(
    in  json  contig_annotations,
    in  fasta concat_ref_fasta,
    out tsv   airr_annotations,
    src comp  "cr_vdj martian airr_filter",
)

stage WRITE_CONTIG_OUTS(
    in  json        contig_annotations,
    in  int         total_read_pairs,
    in  json        corrected_bc_counts,
    in  arp.bincode assemblable_reads_per_bc,
    out fastq       contig_fastq,
    out fastq       filtered_contig_fastq,
    out fasta       contig_fasta,
    out fasta.fai   contig_fasta_fai,
    out fasta       filtered_contig_fasta,
    out bed         annotations_bed,
    out json        cell_barcodes,
    out json        paired_cell_barcodes,
    out json        summary,
    src comp        "cr_vdj martian write_contig_outs",
)

stage HANDLE_GEX_CELLS(
    in  json asm_contig_annotations,
    in  csv  filtered_barcodes,
    in  bool is_antibody_only,
    in  bool is_non_targeted_gex,
    out json contig_annotations,
    src comp "cr_vdj martian handle_gex_cells",
)

stage MAKE_FILTER_SWITCH(
    in  bool         disable_count,
    in  bool         is_antibody_only,
    in  bool         is_non_targeted_gex,
    in  bool         multiplet_filter,
    in  bool         shared_contig_filter,
    in  bool         umi_baseline_filter,
    out FilterSwitch filter_switch,
    src comp         "cr_vdj martian make_filter_switch",
)

stage WRITE_ANN_CSV(
    in  json all_contig_annotations_json,
    out csv  all_contig_annotations_csv,
    out csv  filtered_contig_annotations_csv,
    src comp "cr_vdj martian write_ann_csv",
)

#
# @include "_vloupe_stages.mro"
#

stage VLOUPE_PREPROCESS(
    in  string      pipestance_type,
    in  string      sample_id,
    in  string      sample_desc,
    in  pb          enclone_output,
    in  bool        disable_vloupe,
    in  string      beam_mode,
    in  csv         feature_reference,
    in  h5          feature_barcode_matrix,
    in  csv         antigen_specificity_scores,
    in  map<string> antigen_specificity_controls,
    out vloupe      output_for_vloupe,
    src py          "stages/vloupe/vloupe_preprocess",
) using (
    mem_gb = 15,
)

#
# @include "sc_vdj_aggregator.mro"
#

stage BUILD_AGGR_WEB_SUMMARY(
    in  json content,
    in  json diversity_chart,
    out json web_summary_data,
    src py   "stages/vdj/build_aggr_web_summary",
)

stage CALCULATE_CLONOTYPE_DIVERSITY(
    in  json per_origin_clonotype_hist,
    out json plotly_diversity_chart,
    src py   "stages/vdj/clonotype_diversity",
)

pipeline SC_VDJ_AGGREGATOR(
    in  VdjAggrInput aggr_input,
    in  map          count_gem_well_map,
    in  string       sample_id,
    in  string       sample_desc,
    out pb           enclone_output,
    out string       receptor,
    out csv          clonotypes,
    out fa           donor_ref_fa,
    out fasta        consensus_fasta,
    out path         vdj_reference_path,
    out csv          filt_ann_csv,
    out csv          consensus_ann_csv,
    out json         web_summary_data,
    out vloupe       vloupe,
)
{
    call PROCESS_VDJ_PROTO(
        libraries          = self.aggr_input.libraries,
        count_gem_well_map = self.count_gem_well_map,
    )

    call SETUP_VDJ_AGGR(
        libraries    = self.aggr_input.libraries,
        gem_well_map = PROCESS_VDJ_PROTO.gem_well_map,
        receptor     = PROCESS_VDJ_PROTO.receptor,
    )

    call RUN_ENCLONE_AGGR(
        contig_ann_json_files = SETUP_VDJ_AGGR.contig_ann_json_files,
        enclone_input_csv     = SETUP_VDJ_AGGR.enclone_input_csv,
        enclone_gem_well_meta = SETUP_VDJ_AGGR.enclone_gem_well_meta,
        vdj_reference_path    = SETUP_VDJ_AGGR.vdj_reference_path,
    )

    call WRITE_CONSENSUS_TXT(
        enclone_output = RUN_ENCLONE_AGGR.enclone_output,
    )

    call WRITE_CLONOTYPE_OUTS(
        receptor       = PROCESS_VDJ_PROTO.receptor,
        enclone_output = RUN_ENCLONE_AGGR.enclone_output,
    )

    call FILL_CLONOTYPE_INFO(
        contig_annotations = SETUP_VDJ_AGGR.combined_ann_json,
        enclone_output     = RUN_ENCLONE_AGGR.enclone_output,
    )

    call WRITE_ANN_CSV(
        all_contig_annotations_json = FILL_CLONOTYPE_INFO.all_contig_annotations_json,
    )

    call WRITE_AGGR_ANN(
        enclone_gem_well_meta = SETUP_VDJ_AGGR.enclone_gem_well_meta,
        annotation_csv        = WRITE_ANN_CSV.filtered_contig_annotations_csv,
    )

    call WRITE_WEB_SUMMARY_JSON(
        libraries             = self.aggr_input.libraries,
        enclone_gem_well_meta = SETUP_VDJ_AGGR.enclone_gem_well_meta,
        enclone_output        = RUN_ENCLONE_AGGR.enclone_output,
        sample_id             = self.sample_id,
        sample_desc           = self.sample_desc,
        clonotypes_csv        = WRITE_CLONOTYPE_OUTS.clonotypes_csv,
        receptor              = PROCESS_VDJ_PROTO.receptor,
        vdj_reference_path    = SETUP_VDJ_AGGR.vdj_reference_path,
    )

    call CALCULATE_CLONOTYPE_DIVERSITY(
        per_origin_clonotype_hist = WRITE_WEB_SUMMARY_JSON.per_origin_hist,
    )

    call BUILD_AGGR_WEB_SUMMARY(
        content         = WRITE_WEB_SUMMARY_JSON.web_summary_content,
        diversity_chart = CALCULATE_CLONOTYPE_DIVERSITY.plotly_diversity_chart,
    )

    call VLOUPE_PREPROCESS(
        pipestance_type              = "SC_VDJ_AGGREGATOR",
        sample_id                    = self.sample_id,
        sample_desc                  = self.sample_desc,
        enclone_output               = RUN_ENCLONE_AGGR.enclone_output,
        disable_vloupe               = false,
        beam_mode                    = null,
        feature_reference            = null,
        feature_barcode_matrix       = null,
        antigen_specificity_scores   = null,
        antigen_specificity_controls = null,
    )

    return (
        enclone_output     = RUN_ENCLONE_AGGR.enclone_output,
        receptor           = PROCESS_VDJ_PROTO.receptor,
        clonotypes         = WRITE_CLONOTYPE_OUTS.clonotypes_csv,
        donor_ref_fa       = RUN_ENCLONE_AGGR.donor_ref_fa,
        consensus_fasta    = WRITE_CONSENSUS_TXT.consensus_fasta,
        vdj_reference_path = SETUP_VDJ_AGGR.vdj_reference_path,
        filt_ann_csv       = WRITE_AGGR_ANN.augmented_annotation_csv,
        consensus_ann_csv  = WRITE_CONSENSUS_TXT.consensus_annotations_csv,
        web_summary_data   = BUILD_AGGR_WEB_SUMMARY.web_summary_data,
        vloupe             = VLOUPE_PREPROCESS.output_for_vloupe,
    )
}

#
# @include "_common_cloupe_stages.mro"
#

stage CLOUPE_PREPROCESS(
    in  string pipestance_type,
    in  string sample_id,
    in  string sample_desc,
    in  path   analysis,
    in  h5     filtered_gene_bc_matrices_h5,
    in  json   metrics_json,
    in  csv    aggregation_csv,
    in  json   gem_group_index_json,
    in  path   loupe_alignment_file,
    in  file[] tissue_image_paths,
    in  int    dark_images,
    in  csv    tissue_positions,
    in  txt    fiducial_positions_list,
    in  json   dzi_info,
    in  path[] dzi_tiles_paths,
    in  json   scale_factors_json,
    in  bool   no_secondary_analysis,
    in  string barcode_whitelist,
    in  json   loupe_map,
    in  string product_type,
    in  json   cells_per_sample,
    in  json   cells_per_tag,
    in  json   cells_per_protospacer,
    in  csv    spatial_enrichment,
    out cloupe output_for_cloupe,
    out json   gem_group_index_json,
    src py     "stages/cloupe/cloupe_preprocess",
) split (
) using (
    volatile = strict,
)

#
# @include "rna/sc_rna_aggregator_cs.mro"
#

stage BUILD_COMBINED_WEB_SUMMARY(
    in  json vdj_t_data,
    in  json vdj_b_data,
    in  json vdj_t_gd_data,
    in  json count_data,
    out html web_summary,
    out json web_summary_data,
    src py   "stages/aggregator/build_combined_web_summary",
)

pipeline COUNT_AGGR(
    in  string           sample_id,
    in  string           sample_desc,
    in  map[]            sample_defs,
    in  csv              aggregation_csv,
    in  string           normalization_mode,
    in  bool             no_secondary_analysis,
    in  bool             is_pd,
    out map              gem_group_index,
    out CountAggrOutputs aggr_outputs,
    out json             ws_data,
)
{
    call CHECK_MOLECULE_INFO_VERSION(
        sample_defs  = self.sample_defs,
        product_type = "sc",
    )

    call SC_RNA_AGGREGATOR(
        sample_id             = self.sample_id,
        sample_desc           = self.sample_desc,
        sample_defs           = CHECK_MOLECULE_INFO_VERSION.updated_sample_defs,
        normalization_mode    = self.normalization_mode,
        no_secondary_analysis = self.no_secondary_analysis,
        num_analysis_bcs      = null,
        num_pca_bcs           = null,
        num_pca_genes         = null,
        num_principal_comps   = null,
        cbc_knn               = null,
        cbc_alpha             = null,
        cbc_sigma             = null,
        cbc_realign_panorama  = null,
        max_clusters          = null,
        graphclust_neighbors  = null,
        neighbor_a            = null,
        neighbor_b            = null,
        tsne_perplexity       = null,
        tsne_input_pcs        = null,
        tsne_theta            = null,
        random_seed           = null,
        tsne_max_dims         = null,
        tsne_max_iter         = null,
        tsne_stop_lying_iter  = null,
        tsne_mom_switch_iter  = null,
        product_type          = "sc",
        is_pd                 = self.is_pd,
    )

    call CLOUPE_PREPROCESS(
        pipestance_type              = "SC_RNA_AGGREGATOR_CS",
        sample_id                    = self.sample_id,
        sample_desc                  = self.sample_desc,
        analysis                     = SC_RNA_AGGREGATOR.analysis,
        filtered_gene_bc_matrices_h5 = SC_RNA_AGGREGATOR.filtered_gene_bc_matrices_h5,
        metrics_json                 = SC_RNA_AGGREGATOR.summary,
        aggregation_csv              = self.aggregation_csv,
        gem_group_index_json         = SC_RNA_AGGREGATOR.gem_group_index_json,
        loupe_alignment_file         = null,
        tissue_image_paths           = null,
        dark_images                  = null,
        tissue_positions             = null,
        fiducial_positions_list      = null,
        dzi_info                     = null,
        dzi_tiles_paths              = null,
        scale_factors_json           = null,
        no_secondary_analysis        = self.no_secondary_analysis,
        barcode_whitelist            = null,
        loupe_map                    = null,
        product_type                 = "sc",
        cells_per_sample             = null,
        cells_per_tag                = null,
        cells_per_protospacer        = null,
        spatial_enrichment           = null,
    )

    return (
        gem_group_index = SC_RNA_AGGREGATOR.gem_group_index,
        ws_data         = SC_RNA_AGGREGATOR.web_summary_data,
        aggr_outputs    = {
            analysis:                      SC_RNA_AGGREGATOR.analysis_csv,
            cloupe:                        CLOUPE_PREPROCESS.output_for_cloupe,
            crispr_analysis:               SC_RNA_AGGREGATOR.crispr_analysis,
            filtered_feature_bc_matrix:    SC_RNA_AGGREGATOR.filtered_gene_bc_matrices_mex,
            filtered_feature_bc_matrix_h5: SC_RNA_AGGREGATOR.filtered_gene_bc_matrices_h5,
            summary:                       SC_RNA_AGGREGATOR.summary,
        },
    )
}

pipeline VDJ_AGGR(
    in  VdjAggrInput[] aggr_inputs,
    in  map            gem_group_index,
    in  string         sample_id,
    in  string         sample_desc,
    out VdjAggrOutputs vdj_t_outputs,
    out json           vdj_t_ws_data,
    out VdjAggrOutputs vdj_t_gd_outputs,
    out json           vdj_t_gd_ws_data,
    out VdjAggrOutputs vdj_b_outputs,
    out json           vdj_b_ws_data,
    out VdjRefFolder   vdj_reference,
)
{
    map call SC_VDJ_AGGREGATOR(
        aggr_input         = split self.aggr_inputs,
        count_gem_well_map = self.gem_group_index,
        sample_id          = self.sample_id,
        sample_desc        = self.sample_desc,
    )

    call MATCH_VDJ_AGGR_OUTS(
        receptors                  = SC_VDJ_AGGREGATOR.receptor,
        clonotypes                 = SC_VDJ_AGGREGATOR.clonotypes,
        donor_ref_fas              = SC_VDJ_AGGREGATOR.donor_ref_fa,
        consensus_fastas           = SC_VDJ_AGGREGATOR.consensus_fasta,
        vdj_reference_paths        = SC_VDJ_AGGREGATOR.vdj_reference_path,
        filtered_contig_annotations_csvs = SC_VDJ_AGGREGATOR.filt_ann_csv,
        consensus_annotations_csvs = SC_VDJ_AGGREGATOR.consensus_ann_csv,
        web_summary_data           = SC_VDJ_AGGREGATOR.web_summary_data,
        vloupes                    = SC_VDJ_AGGREGATOR.vloupe,
    )

    call COPY_VDJ_REFERENCE(
        vdj_reference_path    = MATCH_VDJ_AGGR_OUTS.vdj_reference_path,
        vdj_t_donor_ref_fa    = MATCH_VDJ_AGGR_OUTS.vdj_t_results.donor_ref_fa,
        vdj_t_gd_donor_ref_fa = MATCH_VDJ_AGGR_OUTS.vdj_t_gd_results.donor_ref_fa,
        vdj_b_donor_ref_fa    = MATCH_VDJ_AGGR_OUTS.vdj_b_results.donor_ref_fa,
    )

    return (
        vdj_t_outputs    = MATCH_VDJ_AGGR_OUTS.vdj_t_results,
        vdj_t_ws_data    = MATCH_VDJ_AGGR_OUTS.vdj_t_results.web_summary_data,
        vdj_t_gd_outputs = MATCH_VDJ_AGGR_OUTS.vdj_t_gd_results,
        vdj_t_gd_ws_data = MATCH_VDJ_AGGR_OUTS.vdj_t_gd_results.web_summary_data,
        vdj_b_outputs    = MATCH_VDJ_AGGR_OUTS.vdj_b_results,
        vdj_b_ws_data    = MATCH_VDJ_AGGR_OUTS.vdj_b_results.web_summary_data,
        vdj_reference    = COPY_VDJ_REFERENCE.vdj_reference,
    )
}

pipeline SC_RNA_AGGREGATOR_CS(
    in  string           sample_id,
    in  string           sample_desc,
    in  path             pipestance_root,
    in  csv              aggregation_csv,
    in  string           normalization_mode,
    in  bool             no_secondary_analysis,
    out csv              aggregation_csv        "Copy of the input aggregation CSV"  "aggregation.csv",
    out html             web_summary            "Aggregation metrics summary HTML",
    out CountAggrOutputs count,
    out VdjAggrOutputs   vdj_t,
    out VdjAggrOutputs   vdj_t_gd,
    out VdjAggrOutputs   vdj_b,
    out VdjRefFolder     vdj_reference          "V(D)J reference",
)
{
    call PARSE_AGGR_CSV(
        pipestance_root = self.pipestance_root,
        aggregation_csv = self.aggregation_csv,
    )

    call COUNT_AGGR(
        sample_id             = self.sample_id,
        sample_desc           = self.sample_desc,
        sample_defs           = PARSE_AGGR_CSV.count_libraries,
        aggregation_csv       = self.aggregation_csv,
        normalization_mode    = self.normalization_mode,
        no_secondary_analysis = self.no_secondary_analysis,
        is_pd                 = false,
    ) using (
        disabled = PARSE_AGGR_CSV.disable_count_aggr,
    )

    call VDJ_AGGR(
        aggr_inputs     = PARSE_AGGR_CSV.vdj_aggr_inputs,
        gem_group_index = COUNT_AGGR.gem_group_index,
        sample_id       = self.sample_id,
        sample_desc     = self.sample_desc,
    ) using (
        disabled = PARSE_AGGR_CSV.disable_vdj_aggr,
    )

    call BUILD_COMBINED_WEB_SUMMARY(
        vdj_t_data    = VDJ_AGGR.vdj_t_ws_data,
        vdj_t_gd_data = VDJ_AGGR.vdj_t_gd_ws_data,
        vdj_b_data    = VDJ_AGGR.vdj_b_ws_data,
        count_data    = COUNT_AGGR.ws_data,
    )

    return (
        aggregation_csv = PARSE_AGGR_CSV.aggregation_csv,
        web_summary     = BUILD_COMBINED_WEB_SUMMARY.web_summary,
        count           = COUNT_AGGR.aggr_outputs,
        vdj_t           = VDJ_AGGR.vdj_t_outputs,
        vdj_t_gd        = VDJ_AGGR.vdj_t_gd_outputs,
        vdj_b           = VDJ_AGGR.vdj_b_outputs,
        vdj_reference   = VDJ_AGGR.vdj_reference,
    )
}

#
# @include "__all_pooled.mro"
#

call SC_RNA_AGGREGATOR_CS(
    sample_id             = "all_pooled",
    sample_desc           = "",
    pipestance_root       = "/pl/active/onishimura_lab/PROJECTS/JessicaH/scRNAseq_mixed_stage_embryos_2022-JLH",
    aggregation_csv       = "/pl/active/onishimura_lab/PROJECTS/JessicaH/scRNAseq_mixed_stage_embryos_2022-JLH/aggregation_all.csv",
    normalization_mode    = "mapped",
    no_secondary_analysis = false,
)
